{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"flight-delays-fall-2018/flight_delays_train.csv.zip\", compression='zip')\n",
    "test = pd.read_csv(\"flight-delays-fall-2018/flight_delays_test.csv.zip\", compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train, test], ignore_index=True)\n",
    "all_data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change target name to make it easier\n",
    "train = train.rename(columns={'dep_delayed_15min':'delayed'})\n",
    "all_data = all_data.rename(columns={'dep_delayed_15min':'delayed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change target to numerical N-->0 & Y-->1\n",
    "train.loc[(train.delayed == 'N'), 'delayed'] = 0\n",
    "train.loc[(train.delayed == 'Y'), 'delayed'] = 1\n",
    "all_data.loc[(all_data.delayed == 'N'), 'delayed'] = 0\n",
    "all_data.loc[(all_data.delayed == 'Y'), 'delayed'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['DayofMonth'] = train['DayofMonth'].str.split('-').str[1]\n",
    "train['Month'] = train['Month'].str.split('-').str[1]\n",
    "train['DayOfWeek'] = train['DayOfWeek'].str.split('-').str[1]\n",
    "\n",
    "all_data['DayofMonth'] = all_data['DayofMonth'].str.split('-').str[1]\n",
    "all_data['Month'] = all_data['Month'].str.split('-').str[1]\n",
    "all_data['DayOfWeek'] = all_data['DayOfWeek'].str.split('-').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_count_1 = (all_data['delayed'] == 1).sum()\n",
    "delayed_count_0 = (all_data['delayed'] == 0).sum()\n",
    "\n",
    "print(f\"The count of '1's in 'delayed' column is: {delayed_count_1}\")\n",
    "print(f\"The count of '0's in 'delayed' column is: {delayed_count_0}\")\n",
    "\n",
    "\n",
    "plt.bar(['Not Delayed', 'Delayed'], [delayed_count_0, delayed_count_1], color=['blue', 'red'])\n",
    "plt.title('Flight Delay Status Count')\n",
    "plt.xlabel('Status')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = range(1, 13)\n",
    "fig , ax = plt.subplots(1, 2, figsize=(8,2))\n",
    "sns.countplot(data=train, x='Month', order=order, ax=ax[0])\n",
    "ax[0].set_title('Nb of flights by month')\n",
    "sns.countplot(data=train, x='Month', hue='delayed', order=order, ax=ax[1])\n",
    "ax[1].set_title('Delayed/Not delayed flights by month')\n",
    "plt.figure(figsize=(8,2))\n",
    "sns.barplot(data=train, x = 'Month', y = 'delayed',order=order )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，所有月份的航班数量和延误数量几乎相同。不过，六月、七月和十二月的延迟率略高，可能是由于假期原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = range(1, 32)\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(8,8))\n",
    "sns.countplot(x='DayofMonth', data=train, ax=ax[0],order=order)\n",
    "ax[0].set_title('Nb of flights by day of month')\n",
    "sns.countplot(x='DayofMonth', hue='delayed', data=train, ax=ax[1],order=order)\n",
    "ax[1].set_title('Delayed/not Delayed flight by day of month')\n",
    "sns.barplot(x='DayofMonth', y='delayed', data=train, ax=ax[2], order=order)\n",
    "ax[2].set_title('Rate of delayed flights by day of month')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，很难说每个月的日子之间是否存在很大差异但是，我们可以说，在该月的最后几天，延迟率较高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = range(1,8)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(11,3))\n",
    "sns.countplot(x='DayOfWeek', data=train, ax=ax[0],order=order)\n",
    "ax[0].set_title('Nb of flights by day of week')\n",
    "sns.countplot(x='DayOfWeek', hue='delayed', data=train, ax=ax[1],order=order)\n",
    "ax[1].set_title('Delayed or not flights by day of week')\n",
    "sns.barplot(x='DayOfWeek', y='delayed', data=train, ax=ax[2],order=order)   \n",
    "ax[2].set_title('Rate of delayed flights by day of week')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里我们可以看到，周四和周五的航班延误率最高，而周二、周三和周六的航班延误率最低"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train.DepTime)\n",
    "plt.xlabel('Departure Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于值范围很大，一旦我们对它进行分类，我们就会回到这个变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(8,8))\n",
    "sns.countplot(x='UniqueCarrier', data=train, ax=ax[0])\n",
    "ax[0].set_title('Nb of flights per unique carrier')\n",
    "sns.countplot(x='UniqueCarrier', hue='delayed', data=train, ax=ax[1])\n",
    "ax[1].set_title('Nb of delayed/not flights by unique carrier')\n",
    "sns.barplot(x='UniqueCarrier',y= 'delayed', data=train, ax=ax[2])\n",
    "ax[2].set_title('Rate of delayed flights by unique carrier')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到UniqueCarrier变量对于延迟有很好的作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定更多的分箱数量\n",
    "plt.hist(train.Distance, bins=100)\n",
    "plt.xlabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，，大多数航班的距离都很短，不到1000英里，标准化和/或缩放此变量是个好主意吗？或者这样差异是否更有意义？也许bin这个变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.hist(all_data['DepTime'], bins=24, alpha=0.6, label='All Flights')\n",
    "plt.hist(all_data[all_data['delayed'] == 1]['DepTime'], bins=24, alpha=0.6, label='Delayed Flights')\n",
    "plt.title('Departure Time Distribution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(all_data['DepTime'], all_data['UniqueCarrier'], c=all_data['delayed'], cmap='coolwarm', alpha=0.5)\n",
    "plt.colorbar(label='Delayed')\n",
    "plt.title('Scatter Plot of Unique Carriers vs Departure Time with Delay Colormap')\n",
    "plt.xlabel('Departure Time')\n",
    "plt.ylabel('Unique Carrier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Month'] = all_data['Month'].astype(int)\n",
    "all_data['DayofMonth'] = all_data['DayofMonth'].astype(int)\n",
    "all_data['DayOfWeek'] = all_data['DayOfWeek'].astype(int)\n",
    "# 确保其他布尔列已经被转换为0和1\n",
    "all_data.replace(to_replace=[False, True], value=[0, 1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['flight'] = all_data['Origin'] + '->' + all_data['Dest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 将分类变量编码为数值变量\n",
    "label_encoder = LabelEncoder()\n",
    "all_data['UniqueCarrier'] = label_encoder.fit_transform(all_data['UniqueCarrier'])\n",
    "all_data['Origin'] = label_encoder.fit_transform(all_data['Origin'])\n",
    "all_data['Dest'] = label_encoder.fit_transform(all_data['Dest'])\n",
    "\n",
    "all_data['flight'] = label_encoder.fit_transform(all_data['flight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "correlation_matrix = all_data[all_data.columns].corr()\n",
    "\n",
    "# 使用热力图可视化相关系数矩阵\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', square=True, cbar_kws={\"shrink\": .5})\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 初始化StandardScaler对象\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 提取distance和deptime列的数据，创建一个新数据框\n",
    "to_scale = all_data[['Distance', 'DepTime']]\n",
    "\n",
    "# 使用scaler对象对这两列数据进行标准化\n",
    "scaled_data = scaler.fit_transform(to_scale)\n",
    "\n",
    "# 将标准化后的数据转换回DataFrame并替换原有的列\n",
    "all_data[['Distance', 'DepTime']] = pd.DataFrame(scaled_data, columns=['Distance', 'DepTime'])\n",
    "\n",
    "# 检查标准化后的数据\n",
    "print(all_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import norm, skew \n",
    "plt.style.use('fivethirtyeight')    \n",
    "\n",
    "def draw_dist_prob(data):    \n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(24, 12), dpi=300)\n",
    "    \n",
    "    for i,j in enumerate(['Distance', 'DepTime']):\n",
    "        sns.distplot(data[j], fit=norm, ax=ax[0][i])\n",
    "        (mu, sigma) = norm.fit(data[j])\n",
    "        ax[0][i].legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],loc='best')\n",
    "        ax[0][i].set_ylabel('数量')\n",
    "        ax[0][i].set_title('{} 频数图'.format(j))\n",
    "    \n",
    "        stats.probplot(data[j], plot=ax[1][i])\n",
    "\n",
    "draw_dist_prob(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = all_data.iloc[:100000]\n",
    "new_test = all_data.iloc[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([i for i in zip(new_train.columns,new_train.skew(),new_train.kurt())],\n",
    "             columns=['特征','偏度','峰度'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_train.drop(columns=['delayed'])  # 特征\n",
    "y = new_train['delayed']  # 目标变量\n",
    "\n",
    "# 将数据拆分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)\n",
    "\n",
    "print(\"训练集样本数：\", len(X_train))\n",
    "print(\"测试集样本数：\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设Graphviz的可执行文件路径是 /path/to/graphviz/bin\n",
    "graphviz_path = r'C:/_program/Graphviz2.38/bin'\n",
    "\n",
    "# 设置环境变量\n",
    "import os\n",
    "os.environ['PATH'] += os.pathsep + graphviz_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import recall_score, roc_auc_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# 创建一个包含SMOTE和逻辑回归的Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=48)),\n",
    "    ('logistic_regression', LogisticRegression(max_iter=1000, random_state=48))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", y_pred)\n",
    "score = pipeline.score(X_test, y_test)\n",
    "print(\"Score:\", score)\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "print('Recall:', recall)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# 评估模型\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'logistic_regression__C': [0.1, 1, 10],\n",
    "    'logistic_regression__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='recall_macro')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 打印最佳参数和最佳分数\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", y_pred)\n",
    "score = grid_search.score(X_test, y_test)\n",
    "print(\"Score:\", score)\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "print('Recall:', recall)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# 评估模型\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "intercept_ = best_model.named_steps['logistic_regression'].intercept_\n",
    "coef_ = best_model.named_steps['logistic_regression'].coef_\n",
    "\n",
    "print(\"Intercept:\", intercept_)\n",
    "print(\"Coefficients:\\n\", coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(best_model,'model/logistic_regression.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "pos_weight = sum(y_train == 1) / sum(y_train == 0)\n",
    "\n",
    "# 初始化XGBClassifier模型，添加L1和L2正则化，并设置scale_pos_weight\n",
    "XGBR_classifier = XGBClassifier(random_state=48, reg_alpha=0.2, reg_lambda=100.0, \n",
    "                                 scale_pos_weight=pos_weight)\n",
    "\n",
    "# 训练模型\n",
    "XGBR_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = XGBR_classifier.predict(X_test)\n",
    "xgb.plot_importance(XGBR_classifier, importance_type='gain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "xgb.plot_tree(XGBR_classifier, num_trees=48)\n",
    "plt.savefig(\"model/xgb.png\", dpi=3000)  # 保存为 DPI 为 300 的图像\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBR_classifier.fit(X_train, y_train)\n",
    "xgb_y_pred = XGBR_classifier.predict(X_test)\n",
    "print('xgboost混淆矩阵:',confusion_matrix(y_test,xgb_y_pred))\n",
    "print('xgboostf1得分:',f1_score(y_test,xgb_y_pred))\n",
    "rf_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
    "print(\"xgboost准确率：\", rf_accuracy)\n",
    "xgb_recall = recall_score(y_test, xgb_y_pred, average='macro')\n",
    "print(\"xgboost 召回率：\", xgb_recall)\n",
    "print(\"xgboost auc\",roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'gamma': [0.5, 1.0, 1.5],\n",
    "    'scale_pos_weight': [1, 2, 5]  # 根据正负样本比例调整\n",
    "}\n",
    "\n",
    "# 初始化XGBClassifier\n",
    "xgb = XGBClassifier(random_state=48)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 打印最佳参数\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# 使用最佳参数创建新的模型\n",
    "best_xgb = XGBClassifier(**grid_search.best_params_, random_state=48)\n",
    "best_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_y_pred = best_xgb.predict(X_test)\n",
    "print('xgboost混淆矩阵:',confusion_matrix(y_test,xgb_y_pred))\n",
    "print('xgboostf1得分:',f1_score(y_test,xgb_y_pred))\n",
    "rf_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
    "print(\"xgboost准确率：\", rf_accuracy)\n",
    "xgb_recall = recall_score(y_test, xgb_y_pred, average='macro')\n",
    "print(\"xgboost 召回率：\", xgb_recall)\n",
    "print(\"xgboost auc\",roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, roc_auc_score\n",
    "\n",
    "\n",
    "class_weights = {0: sum(y_train == 0) / len(y_train), 1: sum(y_train == 1) / len(y_train)}\n",
    "dtree = DecisionTreeClassifier(random_state=48, class_weight='balanced',min_samples_leaf = 1,min_samples_split=2,criterion='entropy')\n",
    "\n",
    "# 训练模型\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "dt_y_pred = dtree.predict(X_test)\n",
    "\n",
    "# 打印评估指标\n",
    "print('决策树混淆矩阵:', confusion_matrix(y_test, dt_y_pred))\n",
    "print('决策树f1得分:', f1_score(y_test, dt_y_pred, average='macro'))\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(\"决策树准确率：\", dt_accuracy)\n",
    "dt_recall = recall_score(y_test, dt_y_pred, average='macro')\n",
    "print(\"决策树召回率：\", dt_recall)\n",
    "\n",
    "dt_y_pred_proba = dtree.predict_proba(X_test)[:, 1]\n",
    "print(\"决策树 auc:\", roc_auc_score(y_test, dt_y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 定义超参数的搜索空间\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "class_weights = {0: sum(y_train == 0) / len(y_train), 1: sum(y_train == 1) / len(y_train)}\n",
    "\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=48, class_weight='balanced')\n",
    "grid_search = GridSearchCV(estimator=dtree, param_grid=param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"最佳参数:\", grid_search.best_params_)\n",
    "\n",
    "\n",
    "best_dtree = grid_search.best_estimator\n",
    "cv_scores = cross_val_score(best_dtree, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"交叉验证的F1分数:\", cv_scores)\n",
    "\n",
    "# 预测和评估\n",
    "dt_y_pred = best_dtree.predict(X_test)\n",
    "print('决策树混淆矩阵:', confusion_matrix(y_test, dt_y_pred))\n",
    "print('决策树f1得分:', f1_score(y_test, dt_y_pred, average='macro'))\n",
    "print(\"决策树准确率：\", accuracy_score(y_test, dt_y_pred))\n",
    "print(\"决策树召回率：\", recall_score(y_test, dt_y_pred, average='macro'))\n",
    "\n",
    "dt_y_pred_proba = best_dtree.predict_proba(X_test)[:, 1]\n",
    "print(\"决策树 auc:\", roc_auc_score(y_test, dt_y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "# 假设 dtree 是已经训练好的决策树模型\n",
    "\n",
    "# 导出决策树为 dot 格式\n",
    "dot_data = tree.export_graphviz(dtree,\n",
    "                                 feature_names=X_train.columns.tolist(),\n",
    "                                 class_names=np.unique(y_train).astype(str).tolist(),\n",
    "                                 filled=True, rounded=True,\n",
    "                                 special_characters=True)\n",
    "\n",
    "# 将 dot 数据写入文件\n",
    "with open(\"tree.dot\", \"w\") as f:\n",
    "    f.write(dot_data)\n",
    "\n",
    "# 使用 Graphviz 的 dot 命令行工具来生成图像\n",
    "# 您可以在命令行中运行以下命令来生成高分辨率的图像\n",
    "# 例如，生成 DPI 为 300 的 PNG 图像：\n",
    "os.system('dot -Tpng -o output_highres.png tree.dot -Gdpi=1300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"flight-delays-fall-2018/sample_submission.csv.zip\", compression='zip')\n",
    "sample.head(900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test1 = new_test.drop('dep_delayed_15min', axis=1)\n",
    "predictions = best_model.predict_proba(new_test1)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({'id':range(100000),'dep_delayed_15min':predictions})\n",
    "submission.head(900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'flight_delay.csv'\n",
    "\n",
    "submission.to_csv(filename,index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
