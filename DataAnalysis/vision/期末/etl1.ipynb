{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Data\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_path = r'C:\\Users\\yaw\\Desktop\\大三下\\数据可视化\\2023～2024第2学期数据可视化技术考试\\数据集\\2022_Yellow_Taxi_Trip_Data.csv'\n",
    "file2_path = r'C:\\Users\\yaw\\Desktop\\大三下\\数据可视化\\2023～2024第2学期数据可视化技术考试\\数据集\\taxi_zones.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 CSV 文件，默认情况下分隔符为逗号 \",\"\n",
    "df1 = spark.read.csv(file1_path, header=True, inferSchema=True)\n",
    "df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "- 定义一个函数，把将字符串转换为 datetime 对象\n",
    "- 去除异常值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import TimestampType\n",
    "from datetime import datetime\n",
    "\n",
    "# 定义一个函数，将字符串转换为 datetime 对象\n",
    "def parse_datetime(date_str):\n",
    "    return datetime.strptime(date_str, '%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "parse_datetime_udf = udf(parse_datetime, TimestampType())\n",
    "\n",
    "df1 = df1.withColumn('tpep_pickup_datetime', parse_datetime_udf(col(\"tpep_pickup_datetime\")))\n",
    "df1 = df1.withColumn('tpep_dropoff_datetime', parse_datetime_udf(col(\"tpep_dropoff_datetime\")))\n",
    "\n",
    "# 显示转换后的 DataFrame\n",
    "df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "fields = ['trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee']\n",
    "\n",
    "# 初始化 mean_stddev 字典\n",
    "mean_stddev = {}\n",
    "\n",
    "# 从 describe_results 中提取 mean 和 stddev 值\n",
    "for row in df1.describe(*fields).collect():\n",
    "    if row.summary == 'mean':\n",
    "        for field in fields:\n",
    "            mean_stddev[field] = (row[field], None)  # 初始化为平均值和 None 标准差\n",
    "    elif row.summary == 'stddev':\n",
    "        for field in fields:\n",
    "            if mean_stddev[field][1] is None:  # 如果标准差尚未设置\n",
    "                mean_stddev[field] = (mean_stddev[field][0], row[field])\n",
    "\n",
    "\n",
    "filter_condition_str = \"\"\n",
    "\n",
    "for field in fields:\n",
    "    # 从字典中获取字段的平均值和标准差\n",
    "    mean, stddev = mean_stddev[field]\n",
    "\n",
    "    min_value = float(mean) - 3 * float(stddev)\n",
    "    max_value = float(mean) + 3 * float(stddev)\n",
    "\n",
    "    # 将过滤条件添加到字符串\n",
    "    if filter_condition_str: \n",
    "        filter_condition_str += \" AND \"\n",
    "    filter_condition_str += f\"{field} >= {min_value} AND {field} <= {max_value}\"\n",
    "\n",
    "\n",
    "filtered_df = df1.filter(expr(filter_condition_str))\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.filter(col(\"passenger_count\") > 0)\n",
    "filtered_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 时间段 与 行程数 关系 heatmap calendar\n",
    "- month\n",
    "- dayOfWeek\n",
    "- hour\n",
    "- dayOfMonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofweek, month, hour, dayofmonth, substring\n",
    "\n",
    "df_with_datetime = filtered_df.withColumn('pickup_dayOfWeek', dayofweek(col('tpep_pickup_datetime')))\n",
    "df_with_datetime = df_with_datetime.withColumn('pickup_month', month(col('tpep_pickup_datetime')))\n",
    "df_with_datetime = df_with_datetime.withColumn('pickup_dayOfMonth', dayofmonth(col('tpep_pickup_datetime')))\n",
    "df_with_datetime = df_with_datetime.withColumn('pickup_hour', hour(col('tpep_pickup_datetime')))\n",
    "df_with_datetime = df_with_datetime.withColumn('pickup_date', substring(col('tpep_pickup_datetime'), 1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_datetime.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_date = df_with_datetime.selectExpr('pickup_date', \"pickup_dayOfWeek\",'pickup_month','pickup_dayOfMonth','pickup_hour')\n",
    "df_with_date.createOrReplaceTempView(\"df_with_datetime\")\n",
    "df_with_date.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts.charts import Bar\n",
    "from pyecharts import options as opts\n",
    "\n",
    "def bar_chart(colume, title = '柱状图'):\n",
    "    data = spark.sql(\n",
    "                f\"\"\"\n",
    "                select {colume}, count(*) as count\n",
    "                from df_with_datetime\n",
    "                group by {colume}\n",
    "                order by {colume}\n",
    "                \"\"\"\n",
    "    )\n",
    "    data_df = data.toPandas()\n",
    "\n",
    "    # 使用 pyecharts 绘制柱状图\n",
    "    bar = (\n",
    "        Bar()\n",
    "        .add_xaxis(data_df[colume].tolist())  # 直接使用 DataFrame 列\n",
    "        .add_yaxis(\"Count\", data_df['count'].tolist()\n",
    "                   ,label_opts=opts.LabelOpts(is_show=False)  # 隐藏数据标签\n",
    "                   )\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(title= title),  # 图表标题\n",
    "            xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=45))  # X轴标签旋转\n",
    "        )\n",
    "    )\n",
    "\n",
    "    bar.render(f'image/{title}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('pickup_dayOfMonth', 'pickup_dayOfMonth')\n",
    "bar_chart('pickup_dayOfWeek', 'pickup_dayOfWeek')\n",
    "bar_chart('pickup_hour', 'pickup_hour')\n",
    "bar_chart('pickup_month', 'pickup_month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 行程距离与总费用的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.createOrReplaceTempView(\"df\")\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_distanceAndAmount = spark.sql(\n",
    "    '''\n",
    "    select trip_distance\n",
    "        , round(avg(fare_amount),2) as fare_avg_amount\n",
    "        , round(avg(total_amount),2) as total_avg_amount\n",
    "        , round(avg(tolls_amount),2) as tolls_avg_amount\n",
    "        , round(avg(improvement_surcharge),2) as improvement_avg_amount\n",
    "    from df\n",
    "    group by trip_distance\n",
    "    order by trip_distance\n",
    "    '''\n",
    ")\n",
    "\n",
    "# trip_distanceAndAmount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_distanceAndAmount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts.charts import Scatter\n",
    "from pyecharts import options as opts\n",
    "\n",
    "# 将查询结果转换为 pandas DataFrame\n",
    "data_df = trip_distanceAndAmount.toPandas()\n",
    "\n",
    "# 从 DataFrame 中获取数据\n",
    "trip_distance = data_df['trip_distance']\n",
    "fare_avg_amount = data_df['fare_avg_amount']\n",
    "total_avg_amount = data_df['total_avg_amount']\n",
    "tolls_avg_amount = data_df['tolls_avg_amount']\n",
    "improvement_avg_amount = data_df['improvement_avg_amount']\n",
    "\n",
    "# 创建一个 Scatter 对象\n",
    "scatter = (\n",
    "    Scatter()\n",
    "    .add_xaxis(trip_distance.tolist())  # 设置 x 轴数据\n",
    "    .add_yaxis(\"Fare Average Amount\", fare_avg_amount.tolist(), symbol_size=3, label_opts=opts.LabelOpts(is_show=False))\n",
    "    .add_yaxis(\"Total Average Amount\", total_avg_amount.tolist(), symbol_size=3, label_opts=opts.LabelOpts(is_show=False))\n",
    "    .add_yaxis(\"Tolls Average Amount\", tolls_avg_amount.tolist(), symbol_size=3, label_opts=opts.LabelOpts(is_show=False))\n",
    "    .add_yaxis(\"Improvement Average Amount\", improvement_avg_amount.tolist(), symbol_size=3, label_opts=opts.LabelOpts(is_show=False))\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(\n",
    "            title=\"Trip Distance vs Average Amounts\",\n",
    "            pos_left=\"center\",\n",
    "            pos_top=\"top\",\n",
    "            padding=[20, 0, 0, 0]\n",
    "        ),\n",
    "        legend_opts=opts.LegendOpts(orient=\"horizontal\", pos_top=\"bottom\", pos_left=\"center\"),\n",
    "        xaxis_opts=opts.AxisOpts(\n",
    "            axislabel_opts=opts.LabelOpts(rotate=-15),\n",
    "            max_=1213,\n",
    "            min_=0,\n",
    "            type_='value'\n",
    "        ),\n",
    "        yaxis_opts=opts.AxisOpts(name=\"Average Amount\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 渲染图表到 HTML 文件中\n",
    "scatter.render('image/scatter_chart.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts.charts import Scatter\n",
    "from pyecharts import options as opts\n",
    "\n",
    "# 将查询结果转换为 pandas DataFrame\n",
    "data_df = trip_distanceAndAmount.toPandas()\n",
    "\n",
    "# 从 DataFrame 中获取数据\n",
    "trip_distance = data_df['trip_distance']\n",
    "fare_avg_amount = data_df['fare_avg_amount']\n",
    "total_avg_amount = data_df['total_avg_amount']\n",
    "tolls_avg_amount = data_df['tolls_avg_amount']\n",
    "improvement_avg_amount = data_df['improvement_avg_amount']\n",
    "\n",
    "# 创建一个 Scatter 对象\n",
    "scatter = (\n",
    "    Scatter()\n",
    "    .add_xaxis(trip_distance.tolist())  # 设置 x 轴数据\n",
    "    .add_yaxis(\"Fare Average Amount\", fare_avg_amount.tolist(), symbol_size=3, label_opts=opts.LabelOpts(is_show=False))\n",
    "    .add_yaxis(\"Total Average Amount\", total_avg_amount.tolist(), symbol_size=3, label_opts=opts.LabelOpts(is_show=False))\n",
    "    .add_yaxis(\"Tolls Average Amount\", tolls_avg_amount.tolist(), symbol_size=3, label_opts=opts.LabelOpts(is_show=False))\n",
    "    .add_yaxis(\"Improvement Average Amount\", improvement_avg_amount.tolist(), symbol_size=3, label_opts=opts.LabelOpts(is_show=False))\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(\n",
    "            title=\"Trip Distance vs Average Amounts\",\n",
    "            pos_left=\"center\",\n",
    "            pos_top=\"top\",\n",
    "            padding=[20, 0, 0, 0]\n",
    "        ),\n",
    "        legend_opts=opts.LegendOpts(orient=\"horizontal\", pos_top=\"bottom\", pos_left=\"center\"),\n",
    "        xaxis_opts=opts.AxisOpts(\n",
    "            axislabel_opts=opts.LabelOpts(rotate=-15),\n",
    "            max_=200,\n",
    "            min_=0,\n",
    "            type_='value'\n",
    "        ),\n",
    "        yaxis_opts=opts.AxisOpts(name=\"Average Amount\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 渲染图表到 HTML 文件中\n",
    "scatter.render('image/scatter_chart1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyecharts.charts import Line\n",
    "# from pyecharts import options as opts\n",
    "\n",
    "# # 将查询结果转换为 pandas DataFrame\n",
    "# data_df = trip_distanceAndAmount.toPandas()\n",
    "\n",
    "# trip_distance = data_df['trip_distance']\n",
    "# fare_avg_amount = data_df['fare_avg_amount']\n",
    "# total_avg_amount = data_df['total_avg_amount']\n",
    "# tolls_avg_amount = data_df['tolls_avg_amount']\n",
    "# improvement_avg_amount = data_df['improvement_avg_amount']\n",
    "\n",
    "# # 创建一个 Line 对象\n",
    "# line = (\n",
    "#     Line()\n",
    "#     .add_xaxis(trip_distance.tolist())  # 设置 x 轴数据\n",
    "#     .add_yaxis(\"Fare Average Amount\", fare_avg_amount.tolist(), \n",
    "#         symbol=\"emptyCircle\",\n",
    "#         is_symbol_show=True,\n",
    "#         is_smooth=True,\n",
    "#         label_opts=opts.LabelOpts(is_show=False))  # 添加折线图数据系列\n",
    "#     .add_yaxis(\"Total Average Amount\", total_avg_amount.tolist(),\n",
    "#         symbol=\"emptyCircle\",\n",
    "#         is_symbol_show=True,\n",
    "#         is_smooth=True,\n",
    "#         label_opts=opts.LabelOpts(is_show=False))\n",
    "#     .add_yaxis(\"Tolls Average Amount\", tolls_avg_amount.tolist(),\n",
    "#         symbol=\"emptyCircle\",\n",
    "#         is_symbol_show=True,\n",
    "#         is_smooth=True,\n",
    "#         label_opts=opts.LabelOpts(is_show=False))\n",
    "#     .add_yaxis(\"Improvement Average Amount\", improvement_avg_amount.tolist(),\n",
    "#         symbol=\"emptyCircle\",\n",
    "#         is_symbol_show=True,\n",
    "#         is_smooth=True,\n",
    "#         label_opts=opts.LabelOpts(is_show=False))\n",
    "#     .set_global_opts(\n",
    "#         title_opts=opts.TitleOpts(\n",
    "#             title=\"Trip Distance vs Average Amount\",\n",
    "#             pos_left=\"center\",  # 标题水平居中\n",
    "#             pos_top=\"top\",     # 标题在顶部\n",
    "#             padding=[20, 0, 0, 0]  # 调整标题与图表内容的间距\n",
    "#         ),\n",
    "#         legend_opts=opts.LegendOpts(orient=\"horizontal\", pos_top=\"bottom\", pos_left=\"center\"),  # 调整图例位置\n",
    "#         xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=-15), max_=1213, min_=0, type_='value'),\n",
    "#         yaxis_opts=opts.AxisOpts(name=\"Average Amount\")\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # 渲染图表到 HTML 文件中\n",
    "# line.render('image/line_chart.html')  # 注意在 Windows 系统中使用双反斜杠作为路径分隔符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyecharts.charts import Line\n",
    "# from pyecharts import options as opts\n",
    "\n",
    "# # 将查询结果转换为 pandas DataFrame\n",
    "# data_df = trip_distanceAndAmount.toPandas()\n",
    "\n",
    "# trip_distance = data_df['trip_distance']\n",
    "# fare_avg_amount = data_df['fare_avg_amount']\n",
    "\n",
    "# # 创建一个 Line 对象\n",
    "# line = (\n",
    "#     Line()\n",
    "#     .add_xaxis(trip_distance.tolist())  # 设置 x 轴数据\n",
    "#     .add_yaxis(\"Fare Average Amount\", fare_avg_amount.tolist(), \n",
    "#         symbol=\"emptyCircle\",\n",
    "#         is_symbol_show=True,\n",
    "#         is_smooth=True,\n",
    "#         label_opts=opts.LabelOpts(is_show=False))  # 添加折线图数据系列\n",
    "#     .add_yaxis(\"Total Average Amount\", total_avg_amount.tolist(),\n",
    "#         symbol=\"emptyCircle\",\n",
    "#         is_symbol_show=True,\n",
    "#         is_smooth=True,\n",
    "#         label_opts=opts.LabelOpts(is_show=False))\n",
    "#     .add_yaxis(\"Tolls Average Amount\", tolls_avg_amount.tolist(),\n",
    "#         symbol=\"emptyCircle\",\n",
    "#         is_symbol_show=True,\n",
    "#         is_smooth=True,\n",
    "#         label_opts=opts.LabelOpts(is_show=False))\n",
    "#     .add_yaxis(\"Improvement Average Amount\", improvement_avg_amount.tolist(),\n",
    "#         symbol=\"emptyCircle\",\n",
    "#         is_symbol_show=True,\n",
    "#         is_smooth=True,\n",
    "#         label_opts=opts.LabelOpts(is_show=False))\n",
    "#     .set_global_opts(\n",
    "#         title_opts=opts.TitleOpts(\n",
    "#             title=\"Trip Distance vs Average Amount\",\n",
    "#             pos_left=\"center\",  # 标题水平居中\n",
    "#             pos_top=\"top\",     # 标题在顶部\n",
    "#             padding=[20, 0, 0, 0]  # 调整标题与图表内容的间距\n",
    "#         ),\n",
    "#         legend_opts=opts.LegendOpts(orient=\"horizontal\", pos_top=\"bottom\", pos_left=\"center\"),  # 调整图例位置\n",
    "#         xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=-15), max_=120, min_=0, type_='value'),\n",
    "#         yaxis_opts=opts.AxisOpts(name=\"Average Amount\")\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # 渲染图表到 HTML 文件中\n",
    "# line.render('image/line_chart1.html')  # 注意在 Windows 系统中使用双反斜杠作为路径分隔符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 支付方式与小费的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_typeAndTip = spark.sql(\n",
    "    '''\n",
    "    select payment_type \n",
    "         , round(avg(tip_amount), 4) tip_avg_amount\n",
    "         , round(sum(tip_amount),4) tip_sum_amount\n",
    "         , count(1) tip_count\n",
    "    from df\n",
    "    group by payment_type\n",
    "    order by payment_type\n",
    "    '''\n",
    ")\n",
    "\n",
    "payment_typeAndTip.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts.charts import Pie\n",
    "\n",
    "# 选择数据列\n",
    "data_df = payment_typeAndTip.toPandas()\n",
    "categories = data_df['payment_type']\n",
    "data = data_df['tip_avg_amount']\n",
    "\n",
    "# 创建一个 Pie 对象\n",
    "pie = (\n",
    "    Pie()\n",
    "    .add(\n",
    "        series_name=\"Tip Count\",  # 系列名称\n",
    "        data_pair=[list(z) for z in zip(categories, data)],  # 数据项\n",
    "        rosetype=\"radius\",  # 设置为半径模式的玫瑰图\n",
    "        label_opts=opts.LabelOpts(formatter=\"{b}: {d}%\")  # 设置标签格式\n",
    "    )\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"Payment Type Tip Avg Amount\"),  # 图表标题\n",
    "        legend_opts=opts.LegendOpts(orient=\"vertical\", pos_top=\"15%\", pos_left=\"2%\")  # 图例设置\n",
    "    )\n",
    ")\n",
    "\n",
    "# 渲染图表到 HTML 文件中\n",
    "pie.render('image/pie_chart_avg.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts.charts import Pie\n",
    "from pyecharts import options as opts\n",
    "\n",
    "categories = data_df['payment_type']\n",
    "data = data_df['tip_count']\n",
    "\n",
    "# 创建一个 Pie 对象，并设置内外半径来创建环图\n",
    "pie = (\n",
    "    Pie(init_opts=opts.InitOpts(width=\"800px\", height=\"600px\"))\n",
    "    .add(\n",
    "        series_name=\"Tip Count\",  # 系列名称\n",
    "        data_pair=[list(z) for z in zip(categories, data)],  # 数据项\n",
    "        radius=[\"40%\", \"60%\"],  # 设置内外半径，创建环图效果\n",
    "        label_opts=opts.LabelOpts(formatter=\"{b}: {d}%\"),  # 设置标签格式\n",
    "    )\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"Payment Type Tip Count\"),  # 图表标题\n",
    "        legend_opts=opts.LegendOpts(orient=\"vertical\", pos_top=\"15%\", pos_left=\"2%\")  # 图例设置\n",
    "    )\n",
    ")\n",
    "\n",
    "# 渲染图表到 HTML 文件中\n",
    "pie.render('image/pie_chart_count.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts.charts import Pie\n",
    "from pyecharts import options as opts\n",
    "\n",
    "categories = data_df['payment_type']\n",
    "data = data_df['tip_sum_amount']\n",
    "\n",
    "# 创建一个 Pie 对象\n",
    "pie = (\n",
    "    Pie()\n",
    "    .add(\n",
    "        series_name=\"Payment Type\",\n",
    "        data_pair=[list(z) for z in zip(categories, data)],\n",
    "        radius=\"75%\",\n",
    "        label_opts=opts.LabelOpts(\n",
    "            position=\"outside\",\n",
    "            formatter=\"{b}: {d}%\"\n",
    "        ),\n",
    "        tooltip_opts=opts.TooltipOpts(\n",
    "            trigger=\"item\",\n",
    "            formatter=\"{a} <br/>{b} : {c} ({d}%)\"\n",
    "        )\n",
    "    )\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"Payment Type Tip Sum Amount\"),\n",
    "        legend_opts=opts.LegendOpts(orient=\"vertical\", pos_top=\"15%\", pos_left=\"2%\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# 渲染图表到 HTML 文件中\n",
    "pie.render('image/pie_chart_sum.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 起始和结束地点的分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.csv(file2_path, header=True, inferSchema=True)\n",
    "df2.createOrReplaceTempView(\"df2\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = spark.sql(\n",
    "    '''\n",
    "    with b as (\n",
    "        select LocationID, borough\n",
    "        from df2\n",
    "    )\n",
    "    select PULocationID, b1.borough PUborough, DOLocationID, b2.borough DOborough, value\n",
    "    from (\n",
    "        select PULocationID, DOLocationID, count(1) as value\n",
    "        from df\n",
    "        group by PULocationID, DOLocationID\n",
    "    ) t inner join b b1 on t.PULocationID = b1.LocationID\n",
    "    inner join b b2 on t.DOLocationID = b2.LocationID\n",
    "    '''\n",
    ")\n",
    "\n",
    "area.createOrReplaceTempView('area')\n",
    "area.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = spark.sql(\n",
    "    '''\n",
    "    with borough as (\n",
    "            select borough\n",
    "            from df2\n",
    "            group by borough\n",
    "    ),\n",
    "    t as (\n",
    "        select concat('{\n",
    "                            \"name\":\"', borough, '\"\n",
    "                            }'\n",
    "                    )  j\n",
    "        from borough\n",
    "    ) \n",
    "    select concat('[',concat_ws(',',collect_set(j)), ']') categories\n",
    "    from t\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = spark.sql(\n",
    "    \"\"\"\n",
    "    WITH t AS (\n",
    "        SELECT concat('{\n",
    "                            \"source\": \"', PULocationID, '\", \n",
    "                            \"target\": \"', DOLocationID, '\"\n",
    "                        }'\n",
    "                    ) AS j\n",
    "        FROM area\n",
    "    )\n",
    "    SELECT concat('[', concat_ws(',', collect_list(j)), ']') AS links\n",
    "    FROM t\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = spark.sql(\n",
    "    \"\"\"\n",
    "    with area1 AS (\n",
    "        SELECT LocationID, borough, total_quantity,\n",
    "            ceil(100 * total_quantity / sum(total_quantity) over(rows between unbounded preceding and unbounded following)) symbolSize\n",
    "        FROM (\n",
    "            SELECT LocationID, borough, SUM(quantity) as total_quantity  \n",
    "            FROM (\n",
    "                SELECT PULocationID LocationID, PUborough borough, SUM(value) AS quantity FROM area GROUP BY PULocationID, PUborough\n",
    "                union all\n",
    "                SELECT DOLocationID LocationID, DOborough borough, SUM(value) AS quantity FROM area GROUP BY DOLocationID, DOborough\n",
    "            ) t0 \n",
    "            group by LocationID, borough\n",
    "        ) t1\n",
    "    )\n",
    "    , t AS (\n",
    "    SELECT concat(\n",
    "        '{\n",
    "                \"name\": \"', LocationID,'\",\n",
    "                \"symbolSize\":', symbolSize,',\n",
    "                \"draggable\": \"False\",\n",
    "                \"value\":', total_quantity ,',\n",
    "                \"category\": \"', borough ,'\",\n",
    "                \"label\": {\n",
    "                    \"normal\": {\n",
    "                        \"show\": \"True\"\n",
    "                    }\n",
    "                }\n",
    "            }'\n",
    "        ) AS j\n",
    "        FROM area1\n",
    "    )\n",
    "    SELECT concat('[', concat_ws(',', collect_list(j)), ']') AS nodes\n",
    "    FROM t\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.createOrReplaceTempView(\"nodes\")\n",
    "links.createOrReplaceTempView(\"links\")\n",
    "categories.createOrReplaceTempView(\"categories\")\n",
    "\n",
    "json = spark.sql(\n",
    "    '''\n",
    "    select concat('[', concat_ws(',', collect_list(j)), ']') as json\n",
    "    from (\n",
    "        select nodes j from nodes\n",
    "        union all \n",
    "        select links j from links\n",
    "        union all \n",
    "        select categories j from categories\n",
    "    ) t\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假定nodes DataFrame只有一个包含JSON数组的'nodes'列\n",
    "json_content = json.collect()[0][0] \n",
    "\n",
    "# 将提取的JSON内容写入文件\n",
    "with open(\"graph1.json\", \"w\") as f:\n",
    "    f.write(json_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Graph\n",
    "\n",
    "# 假设你的 graph.json 文件包含 nodes, links 和 categories 数据\n",
    "with open(\"graph1.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    j = json.load(f)\n",
    "    nodes = j[0] \n",
    "    links = j[1]  \n",
    "    categories = j[2] if len(j) > 2 else None\n",
    "\n",
    "\n",
    "c = Graph()\n",
    "c.add(\n",
    "    \"\", \n",
    "    nodes=nodes,\n",
    "    links=links,\n",
    "    categories=categories,\n",
    "    repulsion=50,\n",
    "    label_opts=opts.LabelOpts(is_show=False),  # 假设我们不显示标签\n",
    "    linestyle_opts=opts.LineStyleOpts(curve=0.2),  # 设置边的曲线样式\n",
    "    # layout=\"circular\",\n",
    "    # is_rotate_label=True,\n",
    "    # linestyle_opts=opts.LineStyleOpts(color=\"source\", curve=0.3),\n",
    "    # label_opts=opts.LabelOpts(position=\"right\"),\n",
    ")\n",
    "c.set_global_opts(\n",
    "    legend_opts=opts.LegendOpts(is_show=True),  # 隐藏图例\n",
    ")\n",
    "\n",
    "# 渲染图表到HTML文件\n",
    "c.render(\"image/graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 6 地理分析和可视化：分析不同区域的行程数量分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUL = spark.sql(\n",
    "    '''\n",
    "    select LocationID, borough, zone, the_geom, value\n",
    "    from (\n",
    "        select PULocationID, count(*) as value\n",
    "        from df\n",
    "        group by PULocationID\n",
    "    ) t\n",
    "    inner join df2 on df2.LocationID = t.PULocationID\n",
    "    '''\n",
    ")\n",
    "\n",
    "PUL.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "PUL_dict = PUL.collect()\n",
    "\n",
    "# 创建GeoDataFrame\n",
    "# 使用shapely的wkt.loads来解析WKT字符串\n",
    "PUL_gdf = gpd.GeoDataFrame(\n",
    "    [(row['LocationID'], row['borough'], row['zone'], wkt.loads(row['the_geom']), row['value'])\n",
    "     for row in PUL_dict],\n",
    "    columns=['LocationID', 'borough', 'zone', 'geometry', 'value']\n",
    ")\n",
    "\n",
    "# 将几何数据设置为GeoDataFrame的几何列\n",
    "PUL_gdf.set_geometry('geometry', inplace=True)\n",
    "\n",
    "PUL_gdf.crs = \"EPSG:4326\"\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "PUL_gdf.plot(ax=ax, column='value', legend=True, cmap='OrRd')  # 使用OrRd颜色映射\n",
    "plt.title('LocationID Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import GeoJSONDataSource, HoverTool, ColorBar, LinearColorMapper\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.palettes import Sunset11  # 选择一个颜色映射\n",
    "from bokeh.tile_providers import CARTODBPOSITRON_RETINA\n",
    "\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "p = figure(title=\"LocationID Heatmap\", width=800, height=400)\n",
    "p.add_tile(CARTODBPOSITRON_RETINA)\n",
    "PUL_gdf_json = PUL_gdf.to_json()\n",
    "\n",
    "\n",
    "geosource = GeoJSONDataSource(geojson=PUL_gdf_json)\n",
    "mapper = LinearColorMapper(palette=Sunset11, low=min(PUL_gdf['value']), high=max(PUL_gdf['value']))\n",
    "\n",
    "p.patches('xs', 'ys', source=geosource,\n",
    "          fill_color=linear_cmap(field_name='value', palette=Sunset11, low=min(PUL_gdf['value']), high=max(PUL_gdf['value'])),\n",
    "          line_color=None, fill_alpha=0.7)\n",
    "\n",
    "\n",
    "color_bar = ColorBar(color_mapper=mapper, width=8, location=(0, 0))\n",
    "p.add_layout(color_bar, 'right')\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"LocationID\", \"@LocationID\"),\n",
    "    (\"Borough\", \"@borough\"),\n",
    "    (\"Zone\", \"@zone\"),\n",
    "    (\"Value\", \"@value\"),\n",
    "])\n",
    "\n",
    "\n",
    "p.add_tools(hover)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOL = spark.sql(\n",
    "    '''\n",
    "    select LocationID, borough, zone, the_geom, value\n",
    "    from (\n",
    "        select DOLocationID, count(*) as value\n",
    "        from df\n",
    "        group by DOLocationID\n",
    "    ) t\n",
    "    inner join df2 on df2.LocationID = t.DOLocationID\n",
    "    '''\n",
    ")\n",
    "\n",
    "DOL.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设PUL是Spark DataFrame，你已经执行了Spark SQL查询\n",
    "# PUL = spark.sql(...)\n",
    "\n",
    "# 将Spark DataFrame转换为Python字典\n",
    "PUL_dict = DOL.collect()\n",
    "\n",
    "# 创建GeoDataFrame\n",
    "# 使用shapely的wkt.loads来解析WKT字符串\n",
    "PUL_gdf = gpd.GeoDataFrame(\n",
    "    [(row['LocationID'], row['borough'], row['zone'], wkt.loads(row['the_geom']), row['value'])\n",
    "     for row in PUL_dict],\n",
    "    columns=['LocationID', 'borough', 'zone', 'geometry', 'value']\n",
    ")\n",
    "\n",
    "# 将几何数据设置为GeoDataFrame的几何列\n",
    "PUL_gdf.set_geometry('geometry', inplace=True)\n",
    "\n",
    "# 转换坐标系为EPSG:4326\n",
    "PUL_gdf.crs = \"EPSG:4326\"\n",
    "\n",
    "# 使用matplotlib绘制地图\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "PUL_gdf.plot(ax=ax, column='value', legend=True, cmap='OrRd')  # 使用OrRd颜色映射\n",
    "plt.title('LocationID Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import GeoJSONDataSource, HoverTool, ColorBar, LinearColorMapper\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.palettes import Sunset11  # 选择一个颜色映射\n",
    "from bokeh.tile_providers import CARTODBPOSITRON_RETINA\n",
    "\n",
    "# 确保你的notebook环境支持交互式图表\n",
    "output_notebook()\n",
    "\n",
    "# 创建一个Bokeh figure\n",
    "p = figure(title=\"LocationID Heatmap\", width=800, height=400)\n",
    "\n",
    "# 添加底图\n",
    "p.add_tile(CARTODBPOSITRON_RETINA)\n",
    "\n",
    "# 假设PUL_gdf是已经创建好的GeoDataFrame，并且已经设置好CRS\n",
    "PUL_gdf_json = PUL_gdf.to_json()\n",
    "\n",
    "# 创建GeoJSON数据源\n",
    "geosource = GeoJSONDataSource(geojson=PUL_gdf_json)\n",
    "\n",
    "# 使用线性颜色映射器，将数值映射到颜色\n",
    "mapper = LinearColorMapper(palette=Sunset11, low=min(PUL_gdf['value']), high=max(PUL_gdf['value']))\n",
    "\n",
    "# 添加图层，使用颜色映射\n",
    "p.patches('xs', 'ys', source=geosource,\n",
    "          fill_color=linear_cmap(field_name='value', palette=Sunset11, low=min(PUL_gdf['value']), high=max(PUL_gdf['value'])),\n",
    "          line_color=None, fill_alpha=0.7)\n",
    "\n",
    "# 创建颜色条\n",
    "color_bar = ColorBar(color_mapper=mapper, width=8, location=(0, 0))\n",
    "p.add_layout(color_bar, 'right')\n",
    "\n",
    "# 创建Hover工具\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"LocationID\", \"@LocationID\"),\n",
    "    (\"Borough\", \"@borough\"),\n",
    "    (\"Zone\", \"@zone\"),\n",
    "    (\"Value\", \"@value\"),\n",
    "])\n",
    "\n",
    "# 将Hover工具添加到figure\n",
    "p.add_tools(hover)\n",
    "\n",
    "# 显示图表\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUL = spark.sql(\n",
    "    '''\n",
    "    select LocationID, borough, zone, the_geom, sum(value) value\n",
    "    from (\n",
    "        select LocationID, borough, zone, the_geom, -1 * value as value\n",
    "        from (\n",
    "            select PULocationID, count(*) as value\n",
    "            from df\n",
    "            group by PULocationID\n",
    "        ) t\n",
    "        inner join df2 on df2.LocationID = t.PULocationID\n",
    "        union all\n",
    "        select LocationID, borough, zone, the_geom, 1 * value as value\n",
    "        from (\n",
    "            select DOLocationID, count(*) as value\n",
    "            from df\n",
    "            group by DOLocationID\n",
    "        ) t1\n",
    "        inner join df2 on df2.LocationID = t1.DOLocationID\n",
    "    ) t2\n",
    "    group by LocationID, borough, zone, the_geom\n",
    "\n",
    "    '''\n",
    ")\n",
    "\n",
    "PUL.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设PUL是Spark DataFrame，你已经执行了Spark SQL查询\n",
    "# PUL = spark.sql(...)\n",
    "\n",
    "# 将Spark DataFrame转换为Python字典\n",
    "PUL_dict = DOL.collect()\n",
    "\n",
    "# 创建GeoDataFrame\n",
    "# 使用shapely的wkt.loads来解析WKT字符串\n",
    "PUL_gdf = gpd.GeoDataFrame(\n",
    "    [(row['LocationID'], row['borough'], row['zone'], wkt.loads(row['the_geom']), row['value'])\n",
    "     for row in PUL_dict],\n",
    "    columns=['LocationID', 'borough', 'zone', 'geometry', 'value']\n",
    ")\n",
    "\n",
    "# 将几何数据设置为GeoDataFrame的几何列\n",
    "PUL_gdf.set_geometry('geometry', inplace=True)\n",
    "\n",
    "# 转换坐标系为EPSG:4326\n",
    "PUL_gdf.crs = \"EPSG:4326\"\n",
    "\n",
    "# 使用matplotlib绘制地图\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "PUL_gdf.plot(ax=ax, column='value', legend=True, cmap='OrRd')  # 使用OrRd颜色映射\n",
    "plt.title('LocationID Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import GeoJSONDataSource, HoverTool, ColorBar, LinearColorMapper\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.palettes import Sunset11  # 选择一个颜色映射\n",
    "from bokeh.tile_providers import CARTODBPOSITRON_RETINA\n",
    "\n",
    "# 确保你的notebook环境支持交互式图表\n",
    "output_notebook()\n",
    "\n",
    "# 创建一个Bokeh figure\n",
    "p = figure(title=\"LocationID Heatmap\", width=800, height=400)\n",
    "\n",
    "# 添加底图\n",
    "p.add_tile(CARTODBPOSITRON_RETINA)\n",
    "\n",
    "# 假设PUL_gdf是已经创建好的GeoDataFrame，并且已经设置好CRS\n",
    "PUL_gdf_json = PUL_gdf.to_json()\n",
    "\n",
    "# 创建GeoJSON数据源\n",
    "geosource = GeoJSONDataSource(geojson=PUL_gdf_json)\n",
    "\n",
    "# 使用线性颜色映射器，将数值映射到颜色\n",
    "mapper = LinearColorMapper(palette=Sunset11, low=min(PUL_gdf['value']), high=max(PUL_gdf['value']))\n",
    "\n",
    "# 添加图层，使用颜色映射\n",
    "p.patches('xs', 'ys', source=geosource,\n",
    "          fill_color=linear_cmap(field_name='value', palette=Sunset11, low=min(PUL_gdf['value']), high=max(PUL_gdf['value'])),\n",
    "          line_color=None, fill_alpha=0.7)\n",
    "\n",
    "# 创建颜色条\n",
    "color_bar = ColorBar(color_mapper=mapper, width=8, location=(0, 0))\n",
    "p.add_layout(color_bar, 'right')\n",
    "\n",
    "# 创建Hover工具\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"LocationID\", \"@LocationID\"),\n",
    "    (\"Borough\", \"@borough\"),\n",
    "    (\"Zone\", \"@zone\"),\n",
    "    (\"Value\", \"@value\"),\n",
    "])\n",
    "\n",
    "# 将Hover工具添加到figure\n",
    "p.add_tools(hover)\n",
    "\n",
    "# 显示图表\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 车内乘客与车费的关系 水平柱状图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerAndAmount = spark.sql(\n",
    "    '''\n",
    "    SELECT passenger_count \n",
    "            ,round(avg(fare_amount),2) as fatre_avg_amount\n",
    "            , round(avg(tip_amount), 2) as tip_avg_amount\n",
    "            , round(avg(total_amount), 2) as total_avg_amount\n",
    "    FROM df\n",
    "    group by passenger_count\n",
    "    order by passenger_count\n",
    "    '''\n",
    ")\n",
    "\n",
    "passengerAndAmount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts.charts import Bar\n",
    "from pyecharts import options as opts\n",
    "\n",
    "data_df = passengerAndAmount.toPandas()\n",
    "\n",
    "bar = (\n",
    "    Bar()  \n",
    "    .add_xaxis(data_df['passenger_count'].values.tolist())  \n",
    "    .add_yaxis(\"Total Avg Amount\", data_df['total_avg_amount'].values.tolist(),  \n",
    "                label_opts=opts.LabelOpts(is_show=False))  \n",
    "    .add_yaxis(\"Fatre Avg Amount\", data_df['fatre_avg_amount'].values.tolist(),  \n",
    "                label_opts=opts.LabelOpts(is_show=False)) \n",
    "    .add_yaxis(\"Tip Avg Amount\", data_df['tip_avg_amount'].values.tolist(),  \n",
    "                label_opts=opts.LabelOpts(is_show=False)) \n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"PassengerCnt vs Amount\"),  \n",
    "        yaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=45)),  \n",
    "        xaxis_opts=opts.AxisOpts(name=\"Amount\")  \n",
    "    )\n",
    "    .set_series_opts(label_opts=opts.LabelOpts(is_show=False))  \n",
    "    .reversal_axis()  \n",
    ")\n",
    "\n",
    "# 使用字符串格式化来生成文件名\n",
    "bar.render(f'image/passenger_bar_chart.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 供应商与车费关系 rander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RatecodeIDAndAmount = spark.sql(\n",
    "    '''\n",
    "    SELECT RatecodeID\n",
    "        , COUNT(*) AS count\n",
    "        , ROUND(AVG(fare_amount), 2) AS fare_avg_amount\n",
    "        , ROUND(AVG(tip_amount), 2) AS tip_avg_amount\n",
    "        , ROUND(AVG(tolls_amount), 2) AS tolls_avg_amount\n",
    "        , ROUND(AVG(improvement_surcharge), 2) AS improvement_avg_amount\n",
    "        , ROUND(AVG(total_amount), 2) AS total_avg_amount\n",
    "        , ROUND(AVG(extra), 2) AS extra_avg_amount\n",
    "    FROM df\n",
    "    GROUP BY RatecodeID\n",
    "    ORDER BY RatecodeID\n",
    "    '''\n",
    ")\n",
    "\n",
    "RatecodeIDAndAmount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyecharts.options as opts\n",
    "from pyecharts.charts import Radar\n",
    "from pyecharts.globals import ThemeType\n",
    "\n",
    "\n",
    "pandas_df = RatecodeIDAndAmount.toPandas()\n",
    "\n",
    "data = [list(pandas_df.loc[i, ['fare_avg_amount', 'tip_avg_amount', 'tolls_avg_amount', 'improvement_avg_amount', 'total_avg_amount', 'extra_avg_amount']]) for i in pandas_df.index]\n",
    "indicator = [\"Fare\", \"Tip\", \"Tolls\", \"Improvement Surcharge\", \"Total\", \"Extra\"]\n",
    "\n",
    "# 创建雷达图\n",
    "(\n",
    "    Radar(init_opts=opts.InitOpts(theme=ThemeType.MACARONS))\n",
    "    .add_schema(\n",
    "        schema=[opts.RadarIndicatorItem(name=ind) for ind in indicator],\n",
    "        shape=\"circle\"\n",
    "    )\n",
    "    .add(\n",
    "        series_name=indicator,\n",
    "        data=data\n",
    "    )\n",
    "    .set_series_opts(label_opts=opts.LabelOpts(is_show=False))\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"RatecodeID雷达图\"),\n",
    "    )\n",
    "    .render(\"image/ratecodeid_radar_chart.html\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 congestion_surcharge 与 与高峰时段相关 车费"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeAndcongestion_avg_surcharge = spark.sql(\n",
    "    '''\n",
    "    select time, round(avg(congestion_surcharge), 2) as congestion_avg_surcharge\n",
    "    from (\n",
    "        select hour(tpep_pickup_datetime) * 60 + minute(tpep_pickup_datetime) time, congestion_surcharge\n",
    "        from df\n",
    "    ) t\n",
    "    group by time\n",
    "    order by time\n",
    "    '''\n",
    ")\n",
    "\n",
    "timeAndcongestion_avg_surcharge.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyecharts.charts import Line\n",
    "from pyecharts import options as opts\n",
    "\n",
    "\n",
    "data_dict = timeAndcongestion_avg_surcharge.collect()  \n",
    "\n",
    "times = [row['time'] for row in data_dict]\n",
    "surcharges = [row['congestion_avg_surcharge'] for row in data_dict]\n",
    "\n",
    "line = (\n",
    "    Line()\n",
    "    .add_xaxis(times)\n",
    "    .add_yaxis(\"拥堵费\", surcharges)\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"拥堵费时间序列\"))\n",
    ")\n",
    "\n",
    "# 渲染图表到HTML文件\n",
    "line.render(\"image/congestion_surcharge_line_chart.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
